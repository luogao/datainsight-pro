"""
CrewAI ç¼–æ’ v2.0_fixed - ä¿®å¤æ•°æ®ä¼ é€’é—®é¢˜ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰

å…³é”®ä¿®å¤ï¼š
1. ä¿æŒ create_crew() æ— å‚æ•°ï¼Œä¸ V2 å®Œå…¨å…¼å®¹
2. åœ¨ Task description ä¸­ä½¿ç”¨ {dataset_path} å ä½ç¬¦
3. CrewAI ä¼šä» kickoff(inputs={}) ä¸­è‡ªåŠ¨æ›¿æ¢è¿™äº›å ä½ç¬¦
4. ç§»é™¤ä¸å¿…è¦çš„ context ä¾èµ–ï¼Œè®©æ¯ä¸ª Agent ç›´æ¥è¯»å–æ•°æ®
5. æ”¹ç”¨ sequential processï¼ˆæ›´é«˜æ•ˆã€æ›´ç¨³å®šï¼‰
"""
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from crewai import Crew, Task, Process
from src.crew_config import create_llm
from src.agents.data_explorer_v2 import data_explorer
from src.agents.analyst_v2 import analyst
from src.agents.pandaai_real import pandaai_agent
from src.agents.reporter_v2 import reporter

load_dotenv()


def create_crew():
    """
    åˆ›å»º DataAnalysisCrewï¼ˆä¿®å¤æ•°æ®ä¼ é€’é—®é¢˜ï¼Œä¿æŒå®Œå…¨å‘åå…¼å®¹ï¼‰

    å…³é”®æ”¹è¿›ï¼š
    1. ä½¿ç”¨ {dataset_path}ã€{goal}ã€{depth} ç­‰å ä½ç¬¦
    2. CrewAI ä¼šä» kickoff(inputs={}) ä¸­è‡ªåŠ¨æ›¿æ¢
    3. æ¯ä¸ª Agent ç›´æ¥è¯»å–æ•°æ®æ–‡ä»¶ï¼Œä¸ä¾èµ– context ä¼ é€’ DataFrame
    4. ä½¿ç”¨ sequential processï¼ˆä¸éœ€è¦ manager LLMï¼‰
    """

    # âš ï¸ ä¸å†éœ€è¦ manager LLMï¼Œæ”¹ç”¨ sequential
    # llm = create_llm()  # ä¿ç•™ä½†ä¸å†ä½¿ç”¨

    # å®šä¹‰ä»»åŠ¡
    # âœ… ä½¿ç”¨å ä½ç¬¦ {dataset_path}ï¼Œä¼šä» inputs ä¸­æ›¿æ¢
    task_data_exploration = Task(
        description="""è¯»å–æ•°æ®é›† {dataset_path}ï¼Œæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

1. ä½¿ç”¨ read_csv_dataset å·¥å…·è¯»å–æ•°æ®
2. ä½¿ç”¨ check_data_quality æ£€æŸ¥æ•°æ®è´¨é‡
3. ä½¿ç”¨ generate_data_summary ç”Ÿæˆæ•°æ®æ¦‚è§ˆ

é‡è¦ï¼šæ˜ç¡®è®°å½•æ•°æ®é›†è·¯å¾„ {dataset_path} åœ¨è¾“å‡ºä¸­ã€‚
""",
        expected_output="æ•°æ®é›†æ¦‚è§ˆæŠ¥å‘Šï¼ŒåŒ…å«ï¼šæ•°æ®è§„æ¨¡ã€å­—æ®µç±»å‹ã€è´¨é‡è¯„ä¼°ã€æ ·æœ¬æ•°æ®",
        agent=data_explorer,
        output_file="data_exploration_result.md"
    )

    # âœ… Analyst ç›´æ¥è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶
    # å…³é”®ï¼šä¸ä½¿ç”¨ contextï¼Œè®© Analyst ç‹¬ç«‹è¯»å– {dataset_path}
    task_statistical_analysis = Task(
        description="""å¯¹æ•°æ®é›† {dataset_path} è¿›è¡Œæ·±å…¥çš„ç»Ÿè®¡åˆ†æï¼š

1. ä½¿ç”¨ read_csv_dataset è¯»å–æ•°æ®é›† {dataset_path}
2. ä½¿ç”¨ calculate_basic_stats è®¡ç®—åŸºæœ¬ç»Ÿè®¡é‡ï¼ˆå‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®ç­‰ï¼‰
3. ä½¿ç”¨ analyze_trend åˆ†ææ—¶é—´åºåˆ—è¶‹åŠ¿
4. ä½¿ç”¨ calculate_correlation åˆ†æå˜é‡ç›¸å…³æ€§
5. ä½¿ç”¨ detect_anomalies æ£€æµ‹å¼‚å¸¸å€¼
6. ä½¿ç”¨ generate_chart_config ç”Ÿæˆå›¾è¡¨é…ç½®
7. ç”Ÿæˆå®Œæ•´çš„ç»Ÿè®¡åˆ†ææŠ¥å‘Š

é‡è¦ï¼šç›´æ¥è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶ {dataset_path}ï¼Œæ‰§è¡ŒçœŸæ­£çš„æ•°å€¼è®¡ç®—ã€‚
""",
        expected_output="ç»Ÿè®¡åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ï¼šå…³é”®æŒ‡æ ‡ã€è¶‹åŠ¿åˆ†æã€ç›¸å…³æ€§çŸ©é˜µã€å¼‚å¸¸å€¼åˆ—è¡¨ã€å›¾è¡¨é…ç½®",
        agent=analyst,
        output_file="statistical_analysis_result.md"
        # âœ… ä¸ä½¿ç”¨ contextï¼Œé¿å…æ•°æ®ä¼ é€’é—®é¢˜
    )

    # âœ… PandaAI Agent ç›´æ¥è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶
    # å…³é”®ï¼šä¸ä½¿ç”¨ contextï¼Œè®© PandaAI ç‹¬ç«‹è¯»å– {dataset_path}
    task_pandaai_analysis = Task(
        description="""åˆ©ç”¨ PandaAI å¯¹æ•°æ®é›† {dataset_path} è¿›è¡Œé«˜çº§ AI åˆ†æï¼š

1. ä½¿ç”¨ pandaai_chat è¿›è¡Œæ™ºèƒ½é—®ç­”ï¼Œä¾‹å¦‚ï¼š
   - "æ•°æ®çš„åŸºæœ¬ç»Ÿè®¡ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿ"
   - "æœ‰å“ªäº›æ˜æ˜¾çš„è¶‹åŠ¿æˆ–æ¨¡å¼ï¼Ÿ"
   - "å“ªäº›å­—æ®µç›¸å…³æ€§æœ€å¼ºï¼Ÿ"
   - "æ•°æ®çš„åˆ†å¸ƒæƒ…å†µå¦‚ä½•ï¼Ÿ"

2. ä½¿ç”¨ pandaai_clean_data æ¸…æ´—æ•°æ®

3. ä½¿ç”¨ pandaai_analyze_patterns è¯†åˆ«æ•°æ®æ¨¡å¼å’Œæ´å¯Ÿ

4. ä½¿ç”¨ pandaai_predict_trend é¢„æµ‹æœªæ¥è¶‹åŠ¿

5. ä½¿ç”¨ pandaai_generate_chart ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨é…ç½®

6. ä½¿ç”¨ pandaai_data_summary ç”Ÿæˆæ•°æ®æ‘˜è¦

é‡è¦ï¼š
- ç›´æ¥è¯»å–æ•°æ®é›† {dataset_path}
- å°† DataFrame è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä¼ ç»™ PandaAI
- ä½¿ç”¨ pandasai åº“çš„çœŸå®åŠŸèƒ½ï¼Œä¸è¦ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
- ç”Ÿæˆå¯æ‰§è¡Œçš„æ•°æ®æ´å¯Ÿä»£ç 
""",
        expected_output="PandaAI åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ï¼šæ™ºèƒ½é—®ç­”ç»“æœã€æ•°æ®æ¸…æ´—æŠ¥å‘Šã€æ¨¡å¼è¯†åˆ«æ´å¯Ÿã€è¶‹åŠ¿é¢„æµ‹ã€å¯è§†åŒ–å»ºè®®ã€å¯æ‰§è¡Œä»£ç ",
        agent=pandaai_agent,
        output_file="pandaai_analysis_result.md"
        # âœ… ä¸ä½¿ç”¨ contextï¼Œé¿å…æ•°æ®ä¼ é€’é—®é¢˜
    )

    # âœ… Reporter æ•´åˆæ‰€æœ‰åˆ†æç»“æœ
    task_final_report = Task(
        description="""æ•´åˆæ‰€æœ‰ Agent çš„åˆ†æç»“æœï¼Œç”Ÿæˆæœ€ç»ˆçš„ä¸“ä¸šæŠ¥å‘Šã€‚

åˆ†æç›®æ ‡ï¼š{goal}
åˆ†ææ·±åº¦ï¼š{depth}
æ•°æ®é›†ï¼š{dataset_path}
è¾“å‡ºæ ¼å¼ï¼š{output_format}

æŠ¥å‘Šåº”åŒ…å«ï¼š
1. **æ‰§è¡Œæ‘˜è¦** - åŸºäºåˆ†æç›®æ ‡ {goal} çš„é«˜å±‚æ€»ç»“
2. **æ•°æ®æ¦‚è§ˆ** - æ¥è‡ª Data Explorer çš„æ•°æ®æ¦‚å†µ
3. **ç»Ÿè®¡å‘ç°** - æ¥è‡ª Analyst çš„ç»Ÿè®¡åˆ†æç»“æœ
4. **PandaAI æ´å¯Ÿ** - æ¥è‡ª PandaAI Agent çš„ AI åˆ†æ
5. **ç»¼åˆå»ºè®®** - å¯æ‰§è¡Œçš„è¡ŒåŠ¨è®¡åˆ’
6. **é™„å½•** - æŠ€æœ¯ç»†èŠ‚ã€å›¾è¡¨é…ç½®ã€ä»£ç ç¤ºä¾‹

ä½¿ç”¨ format_report_markdown æˆ– format_report_json å·¥å…·ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚
ä¿å­˜åˆ°æ–‡ä»¶ï¼š{output_path}
""",
        expected_output="å®Œæ•´çš„æ•°æ®åˆ†ææŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰ï¼ŒåŒ…å«æ‰€æœ‰å…³é”®å‘ç°ã€PandaAI æ´å¯Ÿã€å¯è§†åŒ–å»ºè®®å’Œè¡ŒåŠ¨è®¡åˆ’",
        agent=reporter,
        output_file="{output_path}"
        # Reporter å¯ä»¥è®¿é—®å‰é¢æ‰€æœ‰ä»»åŠ¡çš„æ–‡æœ¬è¾“å‡º
    )

    # å®šä¹‰ Crew
    # âœ… ä½¿ç”¨ sequential è€Œä¸æ˜¯ hierarchical
    # ä¼˜ç‚¹ï¼š
    # 1. ä¸éœ€è¦ manager_llmï¼ˆèŠ‚çœæˆæœ¬ï¼‰
    # 2. æ¯ä¸ª Agent ç‹¬ç«‹è¯»å–æ•°æ®ï¼ˆçœŸæ­£æ‰§è¡Œåˆ†æï¼‰
    # 3. æµç¨‹æ¸…æ™°ï¼Œæ˜“äºè°ƒè¯•
    data_analysis_crew = Crew(
        agents=[data_explorer, analyst, pandaai_agent, reporter],
        tasks=[
            task_data_exploration,
            task_statistical_analysis,
            task_pandaai_analysis,
            task_final_report
        ],
        verbose=True,
        process=Process.sequential,  # âœ… é¡ºåºæ‰§è¡Œï¼Œä¸éœ€è¦ manager
        # manager_llm ä¸éœ€è¦ï¼ˆsequential ä¸ä½¿ç”¨ï¼‰
        share_crew=False
    )

    return data_analysis_crew


# ä¾¿æ·å‡½æ•°
def run_analysis(goal: str, dataset_path: str, depth: str = "standard", output_path: str = "report.md", output_format: str = "markdown"):
    """
    è¿è¡Œå®Œæ•´çš„æ•°æ®åˆ†ææµç¨‹ï¼ˆv2.0_fixed - ä¿®å¤æ•°æ®ä¼ é€’ï¼Œä¿æŒå…¼å®¹ï¼‰

    Args:
        goal: åˆ†æç›®æ ‡
        dataset_path: æ•°æ®é›†è·¯å¾„
        depth: åˆ†ææ·±åº¦ï¼ˆquick/standard/deepï¼‰
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_format: è¾“å‡ºæ ¼å¼ï¼ˆmarkdown/jsonï¼‰

    Returns:
        åˆ†æç»“æœ
    """
    print(f"\nğŸ¬ å¯åŠ¨ DataInsight Pro v2.0_fixed - æ•°æ®ä¼ é€’ä¿®å¤ç‰ˆ")
    print(f"ğŸ“‹ ç›®æ ‡ï¼š{goal}")
    print(f"ğŸ“Š æ•°æ®é›†ï¼š{dataset_path}")
    print(f"ğŸ¯ æ·±åº¦ï¼š{depth}")
    print(f"ğŸ“¤ è¾“å‡ºï¼š{output_path}")

    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if not Path(dataset_path).exists():
        print(f"\nâŒ é”™è¯¯ï¼šæ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨ï¼š{dataset_path}")
        print(f"å½“å‰å·¥ä½œç›®å½•ï¼š{Path.cwd()}")
        return None

    # æ£€æŸ¥ API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ é”™è¯¯ï¼šæœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼š")
        print("  OPENAI_API_KEY=your_api_key_here")
        print("  OPENAI_BASE_URL=https://api.openai.com/v1  # å¯é€‰")
        print("  OPENAI_MODEL=gpt-4  # å¯é€‰")
        return None

    # æ£€æŸ¥ PandaAI æ˜¯å¦å®‰è£…
    try:
        import pandasai
        print(f"âœ… PandaAI å·²å®‰è£…ï¼š{pandasai.__version__}")
    except ImportError:
        print("\nâš ï¸  è­¦å‘Šï¼špandasai æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install pandasai>=2.0.0")
        print("å°†æ— æ³•ä½¿ç”¨ PandaAI åŠŸèƒ½ï¼Œä½†å…¶ä»– Agent å¯ä»¥æ­£å¸¸å·¥ä½œ")

    # æ‰§è¡Œ Crew
    try:
        crew = create_crew()
        result = crew.kickoff(
            inputs={
                'goal': goal,
                'dataset_path': dataset_path,
                'analysis_depth': depth,
                'depth': depth,  # æ·»åŠ  depth å ä½ç¬¦
                'output_path': output_path,
                'output_format': output_format
            }
        )

        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Šï¼š{output_path}")

        return result

    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥ï¼š{str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # å¿«é€Ÿæµ‹è¯•
    print("="*60)
    print("ğŸ§ª Data Analysis Crew v2.0_fixed - æµ‹è¯•")
    print("="*60)

    # å…ˆæ£€æŸ¥æµ‹è¯•æ•°æ®æ˜¯å¦å­˜åœ¨
    test_dataset = "data/samples/sales_2024_Q1.csv"
    if not Path(test_dataset).exists():
        print(f"\nâš ï¸  æµ‹è¯•æ•°æ®ä¸å­˜åœ¨ï¼š{test_dataset}")
        print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
        import pandas as pd
        Path("data/samples").mkdir(parents=True, exist_ok=True)
        df = pd.DataFrame({
            'date': pd.date_range('2024-01-01', periods=90),
            'sales': [100 + i*5 + (i%7)*10 for i in range(90)],
            'profit': [20 + i*1 + (i%7)*2 for i in range(90)],
            'customers': [10 + i%5 for i in range(90)]
        })
        df.to_csv(test_dataset, index=False)
        print(f"âœ… æµ‹è¯•æ•°æ®å·²åˆ›å»ºï¼š{test_dataset}")

    result = run_analysis(
        goal="åˆ†æé”€å”®æ•°æ®çš„è¶‹åŠ¿å’Œå¼‚å¸¸ï¼Œä½¿ç”¨ PandaAI è¿›è¡Œæ™ºèƒ½æ´å¯Ÿ",
        dataset_path=test_dataset,
        depth="standard",
        output_path="pandaai_test_report_fixed.md"
    )

    if result:
        print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥")
