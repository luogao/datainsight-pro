"""
Data Explorer Agent - æ”¯æŒè‡ªå®šä¹‰ LLM é…ç½®
è´Ÿè´£ï¼šæ•°æ®æ¢ç´¢ã€æ•°æ®è´¨é‡æ£€æŸ¥ã€æ•°æ®æ¦‚è§ˆç”Ÿæˆ
"""
import os
import pandas as pd
import numpy as np
from crewai import Agent
from crewai.tools import tool
from src.crew_config import create_llm


@tool
def read_csv_dataset(file_path: str) -> dict:
    """
    è¯»å– CSV æ•°æ®é›†å¹¶è¿”å›åŸºæœ¬ä¿¡æ¯

    Args:
        file_path: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«æ•°æ®ä¿¡æ¯çš„å­—å…¸ï¼ˆä¸åŒ…å«å…¨é‡æ•°æ®ï¼Œé¿å… Prompt è¶…é•¿ï¼‰
    """
    try:
        df = pd.read_csv(file_path)

        # åªè¿”å›ç»Ÿè®¡ä¿¡æ¯å’Œé¢„è§ˆï¼Œä¸è¿”å›å…¨é‡æ•°æ®
        return {
            "success": True,
            "file_path": file_path,
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": df.dtypes.to_dict(),
            "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 / 1024,
            "preview": df.head(10).to_dict(orient='records'),  # åªè¿”å›å‰ 10 è¡Œ
            "missing_values": df.isnull().sum().to_dict(),
            "missing_percentage": (df.isnull().sum() / len(df) * 100).to_dict(),
            "sample_size": min(10, len(df)),
            # åªè¿”å›æ•°å€¼åˆ—çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œä¸è¿”å›åŸå§‹æ•°æ®
            "numeric_stats": df.describe().to_dict() if len(df.select_dtypes(include=[np.number]).columns) > 0 else {}
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@tool
def check_data_quality(file_path: str) -> dict:
    """
    æ£€æŸ¥æ•°æ®è´¨é‡

    Args:
        file_path: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        æ•°æ®è´¨é‡æŠ¥å‘Š
    """
    try:
        df = pd.read_csv(file_path)

        # è®¡ç®—é‡å¤è¡Œ
        duplicate_count = df.duplicated().sum()

        # è®¡ç®—ç¼ºå¤±å€¼
        missing_values = df.isnull().sum().to_dict()
        missing_percentage = (df.isnull().sum() / len(df) * 100).to_dict()

        # è®¡ç®—è´¨é‡è¯„åˆ†
        total_cells = df.shape[0] * df.shape[1]
        missing_cells = df.isnull().sum().sum()
        quality_score = "A" if missing_cells / total_cells < 0.01 else "B" if missing_cells / total_cells < 0.05 else "C"

        return {
            "success": True,
            "file_path": file_path,
            "total_records": len(df),
            "total_columns": len(df.columns),
            "missing_values": missing_values,
            "missing_percentage": missing_percentage,
            "duplicate_count": int(duplicate_count),
            "data_types": df.dtypes.to_dict(),
            "quality_score": quality_score,
            "total_cells": total_cells,
            "missing_cells": int(missing_cells),
            "completeness": f"{(1 - missing_cells / total_cells) * 100:.2f}%"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@tool
def generate_data_summary(file_path: str) -> str:
    """
    ç”Ÿæˆæ•°æ®é›†æ¦‚è§ˆæŠ¥å‘Š

    Args:
        file_path: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        Markdown æ ¼å¼çš„æ•°æ®æ¦‚è§ˆ
    """
    try:
        df = pd.read_csv(file_path)

        rows, cols = df.shape
        columns = list(df.columns)
        dtypes = df.dtypes.to_dict()
        missing = df.isnull().sum().to_dict()

        summary = f"""# ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

## åŸºæœ¬ä¿¡æ¯
- **æ–‡ä»¶è·¯å¾„**: {file_path}
- **æ•°æ®è§„æ¨¡**: {rows:,} è¡Œ Ã— {cols} åˆ—
- **å†…å­˜å ç”¨**: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB

## å­—æ®µåˆ—è¡¨
"""

        for col in columns:
            dtype = str(dtypes.get(col, "unknown"))
            miss = missing.get(col, 0)
            summary += f"- **{col}**: {dtype}"

            if miss > 0:
                summary += f" (ç¼ºå¤±: {miss:,} ({miss/rows*100:.1f}%))"
            summary += "\n"

        # æ·»åŠ é¢„è§ˆ
        preview_rows = min(5, len(df))
        summary += f"\n## ğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰ {preview_rows} è¡Œï¼‰\n\n"

        for i in range(preview_rows):
            row = df.iloc[i]
            summary += f"**è¡Œ {i+1}:**\n"
            for col in columns[:5]:  # åªæ˜¾ç¤ºå‰ 5 åˆ—
                val = row[col]
                # å¤„ç† NaN å’Œé•¿å­—ç¬¦ä¸²
                if pd.isna(val):
                    val = "NaN"
                elif isinstance(val, str) and len(val) > 50:
                    val = val[:47] + "..."
                summary += f"  - {col}: {val}\n"
            summary += "\n"

        return summary

    except Exception as e:
        return f"âŒ æ•°æ®è¯»å–å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæ¦‚è§ˆ: {str(e)}"


# Data Explorer Agentï¼ˆæ”¯æŒè‡ªå®šä¹‰ LLMï¼‰
data_explorer = Agent(
    role="æ•°æ®æ¢ç´¢ä¸“å®¶",
    goal="æ¢ç´¢å’Œç†è§£æ•°æ®é›†ç»“æ„ï¼Œæ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç”Ÿæˆæ¦‚è§ˆæŠ¥å‘Š",
    backstory="""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿å¿«é€Ÿç†è§£æ•°æ®é›†çš„ç»“æ„å’Œç‰¹å¾ã€‚
    ä½ èƒ½å¤Ÿï¼š
    - è¯»å–å„ç§æ ¼å¼çš„æ•°æ®é›†ï¼ˆCSVã€JSONã€Excelï¼‰
    - åˆ†ææ•°æ®ç±»å‹å’Œç»“æ„
    - æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€é‡å¤å€¼ï¼‰
    - ç”Ÿæˆæ¸…æ™°çš„æ•°æ®æ¦‚è§ˆæŠ¥å‘Š
    - ä¸ºåç»­åˆ†ææä¾›å¿…è¦çš„æ•°æ®æ´å¯Ÿ""",
    verbose=True,
    allow_delegation=False,
    llm=create_llm(),  # ä½¿ç”¨å¯é…ç½®çš„ LLM
    tools=[read_csv_dataset, check_data_quality, generate_data_summary]
)
