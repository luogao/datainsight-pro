"""
Data Explorer Agent
è´Ÿè´£ï¼šæ•°æ®æ¢ç´¢ã€æ•°æ®è´¨é‡æ£€æŸ¥ã€æ•°æ®æ¦‚è§ˆç”Ÿæˆ
"""
import os
import pandas as pd
import numpy as np
from crewai import Agent, Task, Process
from crewai.tools import SerperDevTool
from langchain.tools import tool


@tool
def read_csv_dataset(file_path: str) -> dict:
    """
    è¯»å– CSV æ•°æ®é›†å¹¶è¿”å›åŸºæœ¬ä¿¡æ¯

    Args:
        file_path: CSV æ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«æ•°æ®ä¿¡æ¯çš„å­—å…¸
    """
    try:
        df = pd.read_csv(file_path)

        return {
            "success": True,
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": df.dtypes.to_dict(),
            "memory_usage": df.memory_usage(deep=True).sum() / 1024 / 1024,  # MB
            "preview": df.head().to_dict(orient='records'),
            "missing_values": df.isnull().sum().to_dict(),
            "sample_size": min(5, len(df))
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@tool
def check_data_quality(df_dict: dict) -> dict:
    """
    æ£€æŸ¥æ•°æ®è´¨é‡

    Args:
        df_dict: åŒ…å«æ•°æ®çš„å­—å…¸ï¼ˆä» read_csv_dataset è¿”å›ï¼‰

    Returns:
        æ•°æ®è´¨é‡æŠ¥å‘Š
    """
    if not df_dict.get("success"):
        return {
            "success": False,
            "error": "Invalid data"
        }

    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä» df_dict ä¸­æå–æ•°æ®
    # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ•°æ®ä¼šåœ¨ Agent é—´ä¼ é€’
    return {
        "total_records": df_dict.get("shape", [0, 0])[0],
        "total_columns": df_dict.get("shape", [0, 0])[1],
        "missing_values": df_dict.get("missing_values", {}),
        "duplicate_count": 0,  # ç®€åŒ–
        "data_types": df_dict.get("dtypes", {}),
        "quality_score": "A"  # ç®€åŒ–
    }


@tool
def generate_data_summary(df_dict: dict) -> str:
    """
    ç”Ÿæˆæ•°æ®é›†æ¦‚è§ˆæŠ¥å‘Š

    Args:
        df_dict: æ•°æ®å­—å…¸

    Returns:
        Markdown æ ¼å¼çš„æ•°æ®æ¦‚è§ˆ
    """
    if not df_dict.get("success"):
        return "âŒ æ•°æ®è¯»å–å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæ¦‚è§ˆ"

    rows, cols = df_dict.get("shape", [0, 0])
    columns = df_dict.get("columns", [])
    dtypes = df_dict.get("dtypes", {})
    missing = df_dict.get("missing_values", {})

    summary = f"""# ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

## åŸºæœ¬ä¿¡æ¯
- **æ•°æ®è§„æ¨¡**: {rows:,} è¡Œ Ã— {cols} åˆ—
- **å†…å­˜å ç”¨**: {df_dict.get('memory_usage', 0):.2f} MB

## å­—æ®µåˆ—è¡¨
"""

    for col in columns:
        dtype = dtypes.get(col, "unknown")
        miss = missing.get(col, 0)
        summary += f"- **{col}**: {dtype}"

        if miss > 0:
            summary += f" (ç¼ºå¤±: {miss:,})"
        summary += "\n"

    # æ·»åŠ é¢„è§ˆ
    preview = df_dict.get("preview", [])
    if preview:
        summary += f"\n## ğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰ {len(preview)} è¡Œï¼‰\n\n"
        for i, row in enumerate(preview):
            summary += f"**è¡Œ {i+1}:**\n"
            for key, value in row.items():
                summary += f"  - {key}: {value}\n"
            summary += "\n"

    return summary


# Data Explorer Agent
data_explorer = Agent(
    role="æ•°æ®æ¢ç´¢ä¸“å®¶",
    goal="æ¢ç´¢å’Œç†è§£æ•°æ®é›†ç»“æ„ï¼Œæ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç”Ÿæˆæ¦‚è§ˆæŠ¥å‘Š",
    backstory="""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿å¿«é€Ÿç†è§£æ•°æ®é›†çš„ç»“æ„å’Œç‰¹å¾ã€‚
    ä½ èƒ½å¤Ÿï¼š
    - è¯»å–å„ç§æ ¼å¼çš„æ•°æ®é›†ï¼ˆCSVã€JSONã€Excelï¼‰
    - åˆ†ææ•°æ®ç±»å‹å’Œç»“æ„
    - æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€é‡å¤å€¼ï¼‰
    - ç”Ÿæˆæ¸…æ™°çš„æ•°æ®æ¦‚è§ˆæŠ¥å‘Š
    - ä¸ºåç»­åˆ†ææä¾›å¿…è¦çš„æ•°æ®æ´å¯Ÿ""",
    verbose=True,
    allow_delegation=False,
    llm="gpt-4",  # å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    tools=[read_csv_dataset, check_data_quality, generate_data_summary]
)
