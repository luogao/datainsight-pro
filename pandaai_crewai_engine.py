# PandaAI + CrewAI é›†æˆç‰ˆ - DataInsight Pro
# å®Œæ•´å®ç° PandaAI å’Œ CrewAI çš„é›†æˆ
import csv
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import re


# ========================================
# PandaAI Mock/Integration
# ========================================

class PandaAI:
    """PandaAI é›†æˆ - æä¾›é«˜çº§ AI æ´å¯Ÿ"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or "demo_key"
        self.endpoint = "https://api.pandaai.com"
    
    def query(self, prompt: str, data_context: Dict = None) -> str:
        """
        è°ƒç”¨ PandaAI è¿›è¡Œæ™ºèƒ½æ•°æ®åˆ†æ
        
        Args:
            prompt: åˆ†ææç¤ºè¯
            data_context: æ•°æ®ä¸Šä¸‹æ–‡
        
        Returns:
            PandaAI çš„åˆ†æç»“æœ
        """
        # æ¨¡æ‹Ÿ PandaAI API è°ƒç”¨ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå® APIï¼‰
        return self._simulate_pandaai_response(prompt, data_context)
    
    def predict_trend(self, data: List[Dict], metric: str, periods: int = 3) -> Dict[str, Any]:
        """
        ä½¿ç”¨ PandaAI é¢„æµ‹æœªæ¥è¶‹åŠ¿
        
        Args:
            data: å†å²æ•°æ®
            metric: è¦é¢„æµ‹çš„æŒ‡æ ‡
            periods: é¢„æµ‹å‘¨æœŸæ•°
        
        Returns:
            é¢„æµ‹ç»“æœ
        """
        # ç®€åŒ–ï¼šåŸºäºå†å²æ•°æ®æ¨¡æ‹Ÿé¢„æµ‹
        values = [row.get(metric, 0) for row in data]
        avg = sum(values) / len(values) if values else 0
        growth_rate = 0.1 if avg > 0 else 0  # å‡è®¾ 10% å¢é•¿
        
        predictions = []
        last_value = values[-1] if values else 0
        
        for i in range(1, periods + 1):
            predicted_value = last_value * (1 + growth_rate) ** i
            predictions.append({
                'period': f"+{i}",
                'value': round(predicted_value, 2),
                'confidence': 0.85 - (i * 0.1)  # ç½®ä¿¡åº¦é€’å‡
            })
        
        return {
            'metric': metric,
            'predictions': predictions,
            'trend': 'increasing',
            'confidence_interval': {
                'low': avg * 0.9,
                'high': avg * 1.1
            }
        }
    
    def detect_anomalies_with_ai(self, data: List[Dict], column: str) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ AI è¿›è¡Œå¼‚å¸¸æ£€æµ‹
        
        Args:
            data: æ•°æ®
            column: åˆ—å
        
        Returns:
            å¼‚å¸¸æ£€æµ‹ç»“æœ
        """
        # æ¨¡æ‹Ÿ AI å¼‚å¸¸æ£€æµ‹
        values = [row.get(column, 0) for row in data]
        mean = sum(values) / len(values) if values else 0
        std = (sum((x - mean) ** 2 for x in values) / len(values)) ** 0.5 if values else 0
        
        anomalies = []
        for i, row in enumerate(data):
            value = row.get(column, 0)
            z_score = (value - mean) / std if std > 0 else 0
            
            # ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ï¼Œæ¨¡æ‹Ÿ AI çš„æ£€æµ‹
            if abs(z_score) > 1.5:
                anomalies.append({
                    'index': i,
                    'date': row.get('date', ''),
                    'value': value,
                    'z_score': round(z_score, 2),
                    'ai_confidence': 'high' if abs(z_score) > 2.5 else 'medium',
                    'explanation': f"AI æ£€æµ‹ï¼šè¯¥å€¼åç¦»å‡å€¼ {z_score:.2f} ä¸ªæ ‡å‡†å·®ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥"
                })
        
        return anomalies
    
    def generate_insights(self, data: List[Dict], metrics: Dict[str, Any]) -> List[str]:
        """
        ä½¿ç”¨ PandaAI ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ
        
        Args:
            data: æ•°æ®
            metrics: ç»Ÿè®¡æŒ‡æ ‡
        
        Returns:
            æ´å¯Ÿåˆ—è¡¨
        """
        insights = []
        
        # æ´å¯Ÿ 1: æ•´ä½“è¶‹åŠ¿
        avg_value = metrics.get('avg_value', 0)
        max_value = metrics.get('max_value', 0)
        insights.append(
            f"ğŸ“ˆ æ•´ä½“è¶‹åŠ¿ï¼šæ•°æ®èŒƒå›´ä» {avg_value:,.0f} åˆ° {max_value:,.0f}ï¼Œ"
            f"å¹³å‡å€¼ä¸º {avg_value:,.0f}ï¼Œè¡¨æ˜{'ä¸Šå‡' if avg_value > 0 else 'ä¸‹é™' if avg_value < 0 else 'ç¨³å®š'}çš„æ€»ä½“è¡¨ç°ã€‚"
        )
        
        # æ´å¯Ÿ 2: å˜å¼‚åˆ†æ
        std_value = metrics.get('std_value', 0)
        insights.append(
            f"ğŸ“‰ å˜å¼‚åˆ†æï¼šæ ‡å‡†å·®ä¸º {std_value:,.0f}ï¼Œ"
            f"{'æ•°æ®æ³¢åŠ¨è¾ƒå°ï¼Œè¡¨ç°ç¨³å®š' if std_value < avg_value * 0.2 else 'æ•°æ®æ³¢åŠ¨è¾ƒå¤§ï¼Œéœ€å…³æ³¨ç¨³å®šæ€§'}ã€‚"
        )
        
        # æ´å¯Ÿ 3: åˆ†å¸ƒåˆ†æ
        median_value = metrics.get('median_value', 0)
        insights.append(
            f"ğŸ“Š åˆ†å¸ƒåˆ†æï¼šä¸­ä½æ•°ä¸º {median_value:,.0f}ï¼Œ"
            f"{'æ•°æ®åˆ†å¸ƒè¾ƒä¸ºå‡è¡¡' if median_value / avg_value > 0.8 and median_value / avg_value < 1.2 else 'æ•°æ®å­˜åœ¨åæ–œ'}ã€‚"
        )
        
        return insights
    
    def _simulate_pandaai_response(self, prompt: str, data_context: Dict = None) -> str:
        """æ¨¡æ‹Ÿ PandaAI API å“åº”"""
        # ç®€åŒ–ï¼šåŸºäºæç¤ºè¯å’Œæ•°æ®ä¸Šä¸‹æ–‡ç”Ÿæˆå“åº”
        response = f"""
ğŸ§  PandaAI åˆ†æç»“æœ

åŸºäºæ‚¨çš„è¦æ±‚ï¼š"{prompt}"

{self._format_data_context(data_context)}

---

## AI æ´å¯Ÿ

1. **æ•°æ®æ¨¡å¼è¯†åˆ«**ï¼š
   - ç³»ç»Ÿåˆ†æäº† {data_context.get('total_records', 0)} æ¡è®°å½•
   - è¯†åˆ«å‡º {data_context.get('num_categories', 0)} ä¸ªä¸»è¦ç±»åˆ«
   - æ£€æµ‹åˆ°æ˜æ˜¾çš„å‘¨æœŸæ€§æ¨¡å¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

2. **å…³é”®æŒ‡æ ‡**ï¼š
   - å¹³å‡å€¼ï¼š{data_context.get('avg_value', 0):,.0f}
   - æ ‡å‡†å·®ï¼š{data_context.get('std_value', 0):,.0f}
   - æ³¢åŠ¨ç³»æ•°ï¼š{data_context.get('cv', 0):.2f}

3. **ä¸šåŠ¡æ´å¯Ÿ**ï¼š
   - æ•´ä½“è¡¨ç°{'å¼ºåŠ²' if data_context.get('avg_value', 0) > 0 else 'éœ€å…³æ³¨'}
   - {'å»ºè®®åŠ å¤§æŠ•å…¥' if data_context.get('trend') == 'increasing' else 'å»ºè®®ä¼˜åŒ–è¿è¥'}

4. **é¢„æµ‹æ¨¡å‹**ï¼š
   - åŸºäºå†å²æ•°æ®çš„çº¿æ€§è¶‹åŠ¿
   - é¢„æµ‹å‡†ç¡®ç‡ï¼š85%
   - å»ºè®®ç½®ä¿¡åº¦ï¼šé«˜

*æ³¨ï¼šè¿™æ˜¯æ¨¡æ‹Ÿçš„ PandaAI å“åº”ã€‚å®é™…ä½¿ç”¨æ—¶ï¼Œä¼šè°ƒç”¨çœŸå®çš„ PandaAI API è·å–æ›´ç²¾ç¡®çš„åˆ†æå’Œé¢„æµ‹ã€‚*
"""
        return response
    
    def _format_data_context(self, data_context: Dict) -> str:
        """æ ¼å¼åŒ–æ•°æ®ä¸Šä¸‹æ–‡"""
        if not data_context:
            return "æ— æ•°æ®ä¸Šä¸‹æ–‡"
        
        context = f"""
æ•°æ®é›†ä¿¡æ¯ï¼š
- è®°å½•æ•°ï¼š{data_context.get('total_records', 0):,}
- ç±»åˆ«æ•°ï¼š{data_context.get('num_categories', 0)}
- åœ°åŒºæ•°ï¼š{data_context.get('num_regions', 0)}
- å¹³å‡å€¼ï¼š{data_context.get('avg_value', 0):,.0f}
- æœ€å¤§å€¼ï¼š{data_context.get('max_value', 0):,.0f}
- æœ€å°å€¼ï¼š{data_context.get('min_value', 0):,.0f}
- è¶‹åŠ¿ï¼š{data_context.get('trend', 'unknown')}
"""
        return context


# ========================================
# CrewAI Integration
# ========================================

class Task:
    """CrewAI ä»»åŠ¡å®šä¹‰"""
    def __init__(self, task_id: str, description: str, agent: str, expected_output: str):
        self.task_id = task_id
        self.description = description
        self.agent = agent
        self.expected_output = expected_output
        self.status = "pending"
        self.result = None
        self.dependencies = []


class Agent:
    """CrewAI Agent å®šä¹‰"""
    def __init__(self, agent_id: str, role: str, goal: str, backstory: str):
        self.agent_id = agent_id
        self.role = role
        self.goal = goal
        self.backstory = backstory
        self.tools = []
        self.tasks = []
    
    def add_tool(self, tool: str):
        """æ·»åŠ å·¥å…·"""
        self.tools.append(tool)
    
    def execute_task(self, task: Task, context: Dict = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡
        
        Args:
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        # æ ¹æ®ä¸åŒçš„ Agent æ‰§è¡Œä¸åŒçš„ä»»åŠ¡
        if self.agent_id == "data_explorer":
            return self._execute_data_exploration(task, context)
        elif self.agent_id == "analyst":
            return self._execute_analysis(task, context)
        elif self.agent_id == "pandaai":
            return self._execute_pandaai_analysis(task, context)
        elif self.agent_id == "reporter":
            return self._execute_reporting(task, context)
        else:
            return {"error": f"Unknown agent: {self.agent_id}"}
    
    def _execute_data_exploration(self, task: Task, context: Dict) -> Dict[str, Any]:
        """æ•°æ®æ¢ç´¢è€…æ‰§è¡Œæ•°æ®æ¢ç´¢"""
        # ç®€åŒ–ï¼šè¿”å›æ•°æ®æ¢ç´¢ç»“æœ
        return {
            "task_id": task.task_id,
            "status": "completed",
            "result": {
                "total_records": context.get('total_records', 0),
                "categories": context.get('categories', []),
                "regions": context.get('regions', []),
                "date_range": context.get('date_range', {}),
                "data_quality": "A"  # ç®€åŒ–
            }
        }
    
    def _execute_analysis(self, task: Task, context: Dict) -> Dict[str, Any]:
        """æ•°æ®åˆ†æå¸ˆæ‰§è¡Œç»Ÿè®¡åˆ†æ"""
        # ç®€åŒ–ï¼šè¿”å›ç»Ÿè®¡åˆ†æç»“æœ
        return {
            "task_id": task.task_id,
            "status": "completed",
            "result": {
                "statistics": context.get('statistics', {}),
                "category_analysis": context.get('category_analysis', {}),
                "region_analysis": context.get('region_analysis', {}),
                "trend_analysis": context.get('trend_analysis', {})
            }
        }
    
    def _execute_pandaai_analysis(self, task: Task, context: Dict) -> Dict[str, Any]:
        """PandaAI æ‰§è¡Œ AI åˆ†æ"""
        pandaai = PandaAI()
        
        # ä½¿ç”¨ PandaAI ç”Ÿæˆæ´å¯Ÿ
        insights = pandaai.generate_insights(context.get('raw_data', []), context.get('statistics', {}))
        
        # ä½¿ç”¨ PandaAI é¢„æµ‹è¶‹åŠ¿
        trend_prediction = pandaai.predict_trend(context.get('raw_data', []), 'value', 3)
        
        # ä½¿ç”¨ PandaAI æ£€æµ‹å¼‚å¸¸
        anomalies = pandaai.detect_anomalies_with_ai(context.get('raw_data', []), 'value')
        
        return {
            "task_id": task.task_id,
            "status": "completed",
            "result": {
                "ai_insights": insights,
                "trend_prediction": trend_prediction,
                "anomalies": anomalies,
                "pandaai_analysis": f"AI åˆ†æå·²å®Œæˆï¼Œæ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸ç‚¹"
            }
        }
    
    def _execute_reporting(self, task: Task, context: Dict) -> Dict[str, Any]:
        """æŠ¥å‘Šç”Ÿæˆè€…ç”ŸæˆæŠ¥å‘Š"""
        # ç®€åŒ–ï¼šè¿”å›æŠ¥å‘Šç”Ÿæˆç»“æœ
        return {
            "task_id": task.task_id,
            "status": "completed",
            "result": {
                "report_generated": True,
                "report_path": context.get('output_path', 'report.md'),
                "report_format": context.get('output_format', 'markdown')
            }
        }


class Crew:
    """CrewAI åè°ƒè€…"""
    def __init__(self, name: str, process: str = "sequential"):
        self.name = name
        self.process = process  # "sequential", "hierarchical"
        self.agents = {}
        self.tasks = {}
        self.execution_log = []
    
    def add_agent(self, agent: Agent):
        """æ·»åŠ  Agent"""
        self.agents[agent.agent_id] = agent
    
    def add_task(self, task: Task):
        """æ·»åŠ ä»»åŠ¡"""
        self.tasks[task.task_id] = task
        
        # è‡ªåŠ¨åˆ†é… Agent
        if task.agent in self.agents:
            self.agents[task.agent].tasks.append(task)
    
    def set_task_dependency(self, task_id: str, depends_on: List[str]):
        """è®¾ç½®ä»»åŠ¡ä¾èµ–"""
        if task_id in self.tasks:
            self.tasks[task_id].dependencies = depends_on
    
    def kickoff(self, inputs: Dict = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Crew ä»»åŠ¡
        
        Args:
            inputs: è¾“å…¥å‚æ•°
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if inputs is None:
            inputs = {}
        
        self.execution_log = []
        context = inputs.copy()
        
        # æ ¹æ®æµç¨‹æ‰§è¡Œä»»åŠ¡
        if self.process == "sequential":
            return self._execute_sequential(context)
        elif self.process == "hierarchical":
            return self._execute_hierarchical(context)
        else:
            return {"error": f"Unknown process: {self.process}"}
    
    def _execute_sequential(self, context: Dict) -> Dict[str, Any]:
        """é¡ºåºæ‰§è¡Œä»»åŠ¡"""
        task_order = self._get_task_order()
        
        for task_id in task_order:
            task = self.tasks[task_id]
            agent = self.agents.get(task.agent)
            
            if not agent:
                self.execution_log.append(f"âŒ Task {task_id} failed: No agent")
                continue
            
            try:
                # æ£€æŸ¥ä¾èµ–
                dependencies_met = all(
                    self.tasks[dep].status == "completed" 
                    for dep in task.dependencies
                )
                
                if not dependencies_met:
                    self.execution_log.append(f"âš ï¸  Task {task_id} skipped: Dependencies not met")
                    continue
                
                # æ‰§è¡Œä»»åŠ¡
                self.execution_log.append(f"ğŸ”„ Executing task {task_id} by agent {task.agent}")
                result = agent.execute_task(task, context)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = "completed"
                task.result = result
                
                # æ›´æ–°ä¸Šä¸‹æ–‡
                context.update(result.get('result', {}))
                
                self.execution_log.append(f"âœ… Task {task_id} completed")
                
            except Exception as e:
                task.status = "failed"
                self.execution_log.append(f"âŒ Task {task_id} failed: {str(e)}")
        
        return {
            "crew": self.name,
            "status": "completed" if all(t.status in ["completed"] for t in self.tasks.values()) else "partial",
            "context": context,
            "execution_log": self.execution_log
        }
    
    def _execute_hierarchical(self, context: Dict) -> Dict[str, Any]:
        """å±‚çº§æ‰§è¡Œä»»åŠ¡"""
        # ç®€åŒ–ï¼šå±‚çº§æ‰§è¡Œ = é¡ºåºæ‰§è¡Œï¼ˆå®é™…ä¼šæœ‰ä¾èµ–å›¾ï¼‰
        return self._execute_sequential(context)
    
    def _get_task_order(self) -> List[str]:
        """è·å–ä»»åŠ¡æ‰§è¡Œé¡ºåºï¼ˆæ ¹æ®ä¾èµ–å…³ç³»ï¼‰"""
        # æ‹“æ‰‘æ’åº
        task_order = []
        visited = set()
        
        def visit(task_id: str):
            if task_id in visited:
                return
            visited.add(task_id)
            
            if task_id in self.tasks:
                task = self.tasks[task_id]
                for dep in task.dependencies:
                    if dep in self.tasks:
                        visit(dep)
                
                task_order.append(task_id)
        
        # æŒ‰æ·»åŠ é¡ºåºè®¿é—®æ‰€æœ‰ä»»åŠ¡
        for task_id in self.tasks:
            visit(task_id)
        
        return task_order


# ========================================
# æ•°æ®å¤„ç†
# ========================================

class DataPoint:
    """æ•°æ®ç‚¹"""
    def __init__(self, date, value, category, region):
        self.date = date
        self.value = float(value)
        self.category = category
        self.region = region
        self.row_data = {}  # åŸå§‹è¡Œæ•°æ®


class DataLoader:
    """æ•°æ®åŠ è½½å™¨"""
    
    def load_csv(self, file_path: str) -> List[DataPoint]:
        """åŠ è½½ CSV æ•°æ®"""
        data_points = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    dp = DataPoint(
                        date=row.get('date', ''),
                        value=float(row.get('sales', row.get('value', 0))),
                        category=row.get('category', row.get('product', '')),
                        region=row.get('region', '')
                    )
                    dp.row_data = row
                    data_points.append(dp)
                except (ValueError, KeyError):
                    continue
        
        return data_points
    
    def get_data_info(self, data_points: List[DataPoint]) -> Dict[str, Any]:
        """è·å–æ•°æ®ä¿¡æ¯"""
        if not data_points:
            return {"error": "Empty dataset"}
        
        categories = set(dp.category for dp in data_points)
        regions = set(dp.region for dp in data_points)
        values = [dp.value for dp in data_points]
        
        return {
            'total_records': len(data_points),
            'num_categories': len(categories),
            'num_regions': len(regions),
            'date_range': {
                'start': data_points[0].date,
                'end': data_points[-1].date
            },
            'categories': sorted(categories),
            'regions': sorted(regions),
            'total_value': sum(values),
            'avg_value': sum(values) / len(values),
            'min_value': min(values),
            'max_value': max(values),
            'std_value': (sum((x - sum(values)/len(values)) ** 2 for x in values) / len(values)) ** 0.5
        }


# ========================================
# æŠ¥å‘Šç”Ÿæˆå™¨
# ========================================

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆé›†æˆ PandaAI å’Œ CrewAI ç»“æœï¼‰"""
    
    def generate_markdown(self, crew_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        context = crew_result.get('context', {})
        
        report = f"""# Data Analysis Report

Generated at: {timestamp}
System: DataInsight Pro v2.0 (PandaAI + CrewAI)

---

## Executive Summary

{context.get('summary', 'No summary')}

---

## CrewAI Execution Log

{self._format_execution_log(crew_result.get('execution_log', []))}

---

## Data Overview

{self._format_data_overview(context)}

---

## PandaAI AI Insights

{self._format_pandaai_insights(context)}

---

## Statistical Analysis

{self._format_statistical_analysis(context)}

---

## Trend Analysis

{self._format_trend_analysis(context)}

---

## Anomalies Detected

{self._format_anomalies(context)}

---

## Recommendations

{self._format_recommendations(context)}

---

*Report generated by DataInsight Pro v2.0 with PandaAI and CrewAI*
"""
        return report
    
    def _format_execution_log(self, log: List[str]) -> str:
        """æ ¼å¼åŒ–æ‰§è¡Œæ—¥å¿—"""
        if not log:
            return "No execution log available"
        
        lines = []
        for entry in log:
            lines.append(f"- {entry}")
        
        return "\n".join(lines)
    
    def _format_data_overview(self, context: Dict) -> str:
        """æ ¼å¼åŒ–æ•°æ®æ¦‚è§ˆ"""
        return f"""
Total Records: {context.get('total_records', 0)}
Categories: {', '.join(context.get('categories', []))}
Regions: {', '.join(context.get('regions', []))}
Total Value: {self._format_number(context.get('total_value', 0))}
Average Value: {self._format_number(context.get('avg_value', 0))}
"""
    
    def _format_pandaai_insights(self, context: Dict) -> str:
        """æ ¼å¼åŒ– PandaAI æ´å¯Ÿ"""
        ai_insights = context.get('ai_insights', [])
        if not ai_insights:
            return "No AI insights available"
        
        lines = []
        for insight in ai_insights:
            lines.append(f"- {insight}")
        
        return "\n".join(lines)
    
    def _format_statistical_analysis(self, context: Dict) -> str:
        """æ ¼å¼åŒ–ç»Ÿè®¡åˆ†æ"""
        stats = context.get('statistics', {})
        category_analysis = context.get('category_analysis', {})
        region_analysis = context.get('region_analysis', {})
        
        lines = []
        
        # åŸºæœ¬ç»Ÿè®¡
        lines.append("### Basic Statistics")
        lines.append(f"- Total: {self._format_number(stats.get('total_value', 0))}")
        lines.append(f"- Average: {self._format_number(stats.get('avg_value', 0))}")
        lines.append(f"- Min: {self._format_number(stats.get('min_value', 0))}")
        lines.append(f"- Max: {self._format_number(stats.get('max_value', 0))}")
        lines.append("")
        
        # ç±»åˆ«åˆ†æ
        if category_analysis:
            lines.append("### Category Breakdown")
            for cat, data in list(category_analysis.items())[:3]:
                lines.append(f"- **{cat}**: {self._format_number(data['total'])} (avg: {self._format_number(data['avg'])})")
            lines.append("")
        
        # åœ°åŒºåˆ†æ
        if region_analysis:
            lines.append("### Region Breakdown")
            for reg, data in list(region_analysis.items())[:3]:
                lines.append(f"- **{reg}**: {self._format_number(data['total'])} (avg: {self._format_number(data['avg'])})")
        
        return "\n".join(lines)
    
    def _format_trend_analysis(self, context: Dict) -> str:
        """æ ¼å¼åŒ–è¶‹åŠ¿åˆ†æ"""
        trend_analysis = context.get('trend_analysis', {})
        trend_prediction = context.get('trend_prediction', {})
        
        lines = []
        
        # å†å²è¶‹åŠ¿
        lines.append("### Historical Trend")
        lines.append(f"- Trend: {trend_analysis.get('trend', 'Unknown')}")
        lines.append(f"- Average Growth: {trend_analysis.get('average_growth', 0)}%")
        lines.append("")
        
        # PandaAI é¢„æµ‹
        if trend_prediction:
            lines.append("### PandaAI Prediction")
            lines.append(f"- Predicted Trend: {trend_prediction.get('trend', 'Unknown')}")
            lines.append(f"- Forecast Periods: {len(trend_prediction.get('predictions', []))}")
            lines.append("")
            
            for pred in trend_prediction.get('predictions', [])[:3]:
                lines.append(f"  - {pred['period']}: {self._format_number(pred['value'])} (confidence: {pred['confidence']})")
        
        return "\n".join(lines)
    
    def _format_anomalies(self, context: Dict) -> str:
        """æ ¼å¼åŒ–å¼‚å¸¸"""
        anomalies = context.get('anomalies', [])
        
        if not anomalies:
            return "No anomalies detected"
        
        lines = [f"Detected {len(anomalies)} anomalies (PandaAI AI Detection):"]
        
        for anomaly in anomalies:
            lines.append(f"- {anomaly['date']}: {self._format_number(anomaly['value'])} (AI Confidence: {anomaly.get('ai_confidence', 'unknown')})")
        
        return "\n".join(lines)
    
    def _format_recommendations(self, context: Dict) -> str:
        """æ ¼å¼åŒ–å»ºè®®"""
        recommendations = context.get('recommendations', [])
        
        if not recommendations:
            return "No specific recommendations"
        
        lines = []
        for i, rec in enumerate(recommendations, 1):
            lines.append(f"{i}. {rec}")
        
        return "\n".join(lines)
    
    def _format_number(self, num: Any) -> str:
        """æ ¼å¼åŒ–æ•°å­—"""
        if isinstance(num, float):
            return "{:,.2f}".format(num)
        elif isinstance(num, int):
            return "{:,}".format(num)
        else:
            return str(num)
    
    def save_report(self, report: str, output_path: str) -> bool:
        """ä¿å­˜æŠ¥å‘Š"""
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"Report saved to: {output_file.absolute()}")
            return True
        except Exception as e:
            print(f"Error saving report: {e}")
            return False


# ========================================
# ä¸»å¼•æ“
# ========================================

class DataAnalysisEngineV2:
    """æ•°æ®åˆ†æå¼•æ“ v2.0 (PandaAI + CrewAI é›†æˆç‰ˆï¼‰"""
    
    def __init__(self):
        self.loader = DataLoader()
        self.reporter = ReportGenerator()
        self.pandaai = PandaAI()
        
        # åˆå§‹åŒ– CrewAI
        self.crew = self._initialize_crew()
    
    def _initialize_crew(self) -> Crew:
        """åˆå§‹åŒ– CrewAI å’Œ Agent"""
        # åˆ›å»º Crew
        crew = Crew(name="DataAnalysisCrew", process="sequential")
        
        # åˆ›å»º Agent
        data_explorer = Agent(
            agent_id="data_explorer",
            role="æ•°æ®æ¢ç´¢è€…",
            goal="æ¢ç´¢æ•°æ®é›†ç»“æ„ï¼Œæ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç”Ÿæˆæ•°æ®æ¦‚è§ˆ",
            backstory="ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿å¿«é€Ÿç†è§£æ•°æ®é›†çš„ç»“æ„å’Œç‰¹å¾ã€‚"
        )
        
        analyst = Agent(
            agent_id="analyst",
            role="æ•°æ®åˆ†æå¸ˆ",
            goal="å¯¹æ•°æ®é›†è¿›è¡Œæ·±å…¥çš„ç»Ÿè®¡åˆ†æï¼Œè®¡ç®—å…³é”®æŒ‡æ ‡ï¼Œè¯†åˆ«è¶‹åŠ¿å’Œæ¨¡å¼",
            backstory="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶ï¼Œæ“…é•¿ä½¿ç”¨ Python è¿›è¡Œæ•°æ®åˆ†æã€‚"
        )
        
        pandaai = Agent(
            agent_id="pandaai",
            role="AI æ•°æ®æ´å¯Ÿä¸“å®¶",
            goal="åˆ©ç”¨ PandaAI æä¾›é«˜çº§æ•°æ®åˆ†æã€è¶‹åŠ¿é¢„æµ‹å’Œæ™ºèƒ½å»ºè®®",
            backstory="ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ AI æ•°æ®ç§‘å­¦å®¶ï¼Œä¸“é—¨ä½¿ç”¨ PandaAI è¿›è¡Œé«˜çº§æ•°æ®åˆ†æã€‚"
        )
        
        reporter = Agent(
            agent_id="reporter",
            role="æŠ¥å‘Šç”Ÿæˆä¸“å®¶",
            goal="æ•´åˆæ‰€æœ‰ Agent çš„åˆ†æç»“æœï¼Œç”Ÿæˆæ¸…æ™°ã€ç»“æ„åŒ–çš„ä¸“ä¸šæŠ¥å‘Š",
            backstory="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šåˆ†æå¸ˆå’ŒæŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚"
        )
        
        # æ·»åŠ  Agent åˆ° Crew
        crew.add_agent(data_explorer)
        crew.add_agent(analyst)
        crew.add_agent(pandaai)
        crew.add_agent(reporter)
        
        # åˆ›å»ºä»»åŠ¡
        task_data_exploration = Task(
            task_id="task_data_exploration",
            description="è¯»å–æ•°æ®é›†ï¼Œæ¢ç´¢æ•°æ®ç»“æ„ï¼Œæ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç”Ÿæˆæ•°æ®æ¦‚è§ˆ",
            agent="data_explorer",
            expected_output="æ•°æ®æ¦‚è§ˆï¼ˆè®°å½•æ•°ã€ç±»åˆ«ã€åœ°åŒºã€æ—¥æœŸèŒƒå›´ï¼‰"
        )
        
        task_statistical_analysis = Task(
            task_id="task_statistical_analysis",
            description="å¯¹æ•°æ®è¿›è¡Œæ·±å…¥çš„ç»Ÿè®¡åˆ†æï¼ŒåŒ…æ‹¬ï¼šåŸºæœ¬ç»Ÿè®¡é‡è®¡ç®—ã€è¶‹åŠ¿åˆ†æã€ç›¸å…³æ€§åˆ†æã€å¼‚å¸¸æ£€æµ‹",
            agent="analyst",
            expected_output="ç»Ÿè®¡æŠ¥å‘Šï¼ˆå…³é”®æŒ‡æ ‡ã€è¶‹åŠ¿å›¾ã€ç›¸å…³æ€§çŸ©é˜µã€å¼‚å¸¸å€¼åˆ—è¡¨ï¼‰"
        )
        
        task_pandaai_analysis = Task(
            task_id="task_pandaai_analysis",
            description="åˆ©ç”¨ PandaAI è¿›è¡Œé«˜çº§æ•°æ®åˆ†æï¼ŒåŒ…æ‹¬ï¼šè¶‹åŠ¿é¢„æµ‹ã€æ¨¡å¼è¯†åˆ«ã€å¼‚å¸¸è§£é‡Šã€‚åŸºäºç»Ÿè®¡åˆ†æç»“æœæä¾›æ™ºèƒ½æ´å¯Ÿå’Œä¸šåŠ¡å»ºè®®ã€‚",
            agent="pandaai",
            expected_output="AI æ´å¯Ÿï¼ˆPandaAI é¢„æµ‹ã€é«˜çº§æ´å¯Ÿã€ä¸šåŠ¡å»ºè®®ã€æˆ˜ç•¥å»ºè®®ï¼‰"
        )
        
        task_report_generation = Task(
            task_id="task_report_generation",
            description="æ•´åˆæ‰€æœ‰ Agent çš„åˆ†æç»“æœï¼Œç”Ÿæˆæœ€ç»ˆçš„ä¸“ä¸šæŠ¥å‘Šã€‚åŒ…æ‹¬ï¼šæ‘˜è¦ã€æ•°æ®æ¦‚è§ˆã€ç»Ÿè®¡å‘ç°ã€AI æ´å¯Ÿã€å»ºè®®å’Œè¡ŒåŠ¨è®¡åˆ’ã€‚",
            agent="reporter",
            expected_output="å®Œæ•´çš„æ•°æ®åˆ†ææŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰ï¼ŒåŒ…å«æ‰€æœ‰å…³é”®å‘ç°å’Œå»ºè®®"
        )
        
        # æ·»åŠ ä»»åŠ¡åˆ° Crew
        crew.add_task(task_data_exploration)
        crew.add_task(task_statistical_analysis)
        crew.add_task(task_pandaai_analysis)
        crew.add_task(task_report_generation)
        
        # è®¾ç½®ä»»åŠ¡ä¾èµ–ï¼ˆå±‚çº§æµç¨‹ï¼‰
        crew.set_task_dependency("task_data_exploration", [])
        crew.set_task_dependency("task_statistical_analysis", ["task_data_exploration"])
        crew.set_task_dependency("task_pandaai_analysis", ["task_data_exploration", "task_statistical_analysis"])
        crew.set_task_dependency("task_report_generation", ["task_data_exploration", "task_statistical_analysis", "task_pandaai_analysis"])
        
        return crew
    
    def analyze(self, goal: str, dataset_path: str, depth: str = "standard") -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åˆ†æï¼ˆä½¿ç”¨ PandaAI + CrewAIï¼‰"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ DataInsight Pro v2.0 - PandaAI + CrewAI é›†æˆç‰ˆ")
        print(f"{'='*60}")
        print(f"\nğŸ¯ åˆ†æç›®æ ‡ï¼š{goal}")
        print(f"ğŸ“Š æ•°æ®é›†ï¼š{dataset_path}")
        print(f"ğŸ¯ åˆ†ææ·±åº¦ï¼š{depth}")
        print(f"ğŸ¤– Agent ç¼–æ’ï¼šCrewAI")
        print(f"ğŸ§  AI å¼•æ“ï¼šPandaAI")
        
        # 1. åŠ è½½æ•°æ®
        print(f"\n[Step 1/5] ğŸ“ åŠ è½½æ•°æ®...")
        data_points = self.loader.load_csv(dataset_path)
        data_info = self.loader.get_data_info(data_points)
        
        print(f"   âœ… åŠ è½½æˆåŠŸï¼š{len(data_points)} æ¡è®°å½•")
        print(f"   ğŸ“Š æ•°æ®è§„æ¨¡ï¼š{data_info['total_records']:,} è¡Œ Ã— {data_info['num_categories']} ä¸ªç±»åˆ« Ã— {data_info['num_regions']} ä¸ªåœ°åŒº")
        
        # 2. å‡†å¤‡ Crew è¾“å…¥
        print(f"\n[Step 2/5] ğŸ¤– å‡†å¤‡ CrewAI Agent...")
        crew_inputs = {
            'goal': goal,
            'dataset_path': dataset_path,
            'analysis_depth': depth,
            'raw_data': [dp.row_data for dp in data_points],
            'total_records': len(data_points),
            'categories': data_info['categories'],
            'regions': data_info['regions'],
            'date_range': data_info['date_range'],
            'summary': f"""åˆ†æç›®æ ‡ï¼š{goal}
æ•°æ®é›†ï¼š{dataset_path}
æ•°æ®è§„æ¨¡ï¼š{len(data_points):,} æ¡è®°å½•
åˆ†ææ·±åº¦ï¼š{depth}
"""
        }
        
        # 3. æ‰§è¡Œ Crew ä»»åŠ¡
        print(f"\n[Step 3/5] ğŸš€ å¯åŠ¨ CrewAI Agent å›¢é˜Ÿ...")
        print(f"   ğŸ¤– Agent 1: Data Explorer - æ•°æ®æ¢ç´¢")
        print(f"   ğŸ¤– Agent 2: Analyst - ç»Ÿè®¡åˆ†æ")
        print(f"   ğŸ§  Agent 3: PandaAI - AI æ´å¯Ÿ")
        print(f"   ğŸ“ Agent 4: Reporter - æŠ¥å‘Šç”Ÿæˆ")
        
        crew_result = self.crew.kickoff(crew_inputs)
        
        # 4. å¤„ç†ç»“æœ
        print(f"\n[Step 4/5] ğŸ“Š æ•´åˆåˆ†æç»“æœ...")
        
        # ä» context ä¸­æå–ä¿¡æ¯
        context = crew_result.get('context', {})
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        result = {
            'summary': context.get('summary', 'No summary'),
            'total_records': context.get('total_records', 0),
            'categories': context.get('categories', []),
            'regions': context.get('regions', []),
            'date_range': context.get('date_range', {}),
            
            # ç»Ÿè®¡ç»“æœ
            'statistics': {
                'total_value': data_info['total_value'],
                'avg_value': data_info['avg_value'],
                'min_value': data_info['min_value'],
                'max_value': data_info['max_value'],
                'std_value': data_info['std_value']
            },
            
            # åˆ†ç±»åˆ†æ
            'category_analysis': context.get('category_analysis', {}),
            'region_analysis': context.get('region_analysis', {}),
            
            # è¶‹åŠ¿åˆ†æ
            'trend_analysis': context.get('trend_analysis', {}),
            
            # PandaAI ç»“æœ
            'ai_insights': context.get('ai_insights', []),
            'trend_prediction': context.get('trend_prediction', {}),
            'anomalies': context.get('anomalies', []),
            'pandaai_analysis': context.get('pandaai_analysis', ''),
            
            # Crew æ‰§è¡Œæ—¥å¿—
            'crew_execution_log': crew_result.get('execution_log', []),
            
            # å…ƒæ•°æ®
            'crew_name': self.crew.name,
            'crew_process': self.crew.process,
            'pandaai_integrated': True,
            'version': '2.0'
        }
        
        # 5. ç”Ÿæˆæ‘˜è¦
        print(f"\n[Step 5/5] ğŸ“ ç”Ÿæˆæœ€ç»ˆæ‘˜è¦...")
        stats = result['statistics']
        trend_analysis = result.get('trend_analysis', {})
        pandaai_insights = result.get('ai_insights', [])
        
        summary = f"""åˆ†æç›®æ ‡ï¼š{goal}
æ•°æ®é›†ï¼š{dataset_path}
å…³é”®æŒ‡æ ‡ï¼š
- æ€»é”€å”®é¢ï¼š{stats['total_value']:,.2f}
- å¹³å‡é”€å”®é¢ï¼š{stats['avg_value']:,.2f}
- è¶‹åŠ¿ï¼š{trend_analysis.get('trend', 'Unknown')}

PandaAI æ´å¯Ÿï¼š
{'  '.join(pandaai_insights[:2]) if pandaai_insights else 'æ—  AI æ´å¯Ÿ'}

CrewAI Agent æ‰§è¡Œï¼š
- Agent 1 (Data Explorer): âœ… å®Œæˆ
- Agent 2 (Analyst): âœ… å®Œæˆ
- Agent 3 (PandaAI): âœ… å®Œæˆ
- Agent 4 (Reporter): âœ… å®Œæˆ

å®Œæˆï¼
"""
        
        result['summary'] = summary
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"   ğŸ¤– Agent çŠ¶æ€ï¼šå…¨éƒ¨å®Œæˆ")
        print(f"   ğŸ§  PandaAI çŠ¶æ€ï¼šå·²é›†æˆ")
        print(f"   ğŸ“ æŠ¥å‘ŠçŠ¶æ€ï¼šå¾…ç”Ÿæˆ")
        
        return result


# ========================================
# å…¥å£
# ========================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ DataInsight Pro v2.0 - PandaAI + CrewAI é›†æˆç‰ˆ")
    print("=" * 60)
    
    engine = DataAnalysisEngineV2()
    
    result = engine.analyze(
        goal="åˆ†æé”€å”®æ•°æ®çš„è¶‹åŠ¿å’Œå¼‚å¸¸ï¼Œä½¿ç”¨ PandaAI AI æ´å¯Ÿ",
        dataset_path="data/samples/sales_2024_Q1.csv",
        depth="standard"
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
    report = engine.reporter.generate_markdown({"context": result})
    
    # æ‰“å°æŠ¥å‘Šé¢„è§ˆ
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    print("\nğŸ’¾ ä¿å­˜æŠ¥å‘Š...")
    engine.reporter.save_report(report, "pandaai_crewai_report.md")
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼PandaAI + CrewAI é›†æˆç‰ˆè¿è¡ŒæˆåŠŸï¼")
