#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯• - éªŒè¯ä¿®å¤åçš„æ•°æ®æµ

ä¸ä¾èµ–å®Œæ•´çš„ CrewAI æ¡†æ¶ï¼Œç›´æ¥æµ‹è¯• Agent èƒ½å¦ç‹¬ç«‹è¯»å–æ•°æ®
"""
import pandas as pd
from pathlib import Path


def test_data_flow():
    """æµ‹è¯•æ¯ä¸ª Agent èƒ½å¦ç‹¬ç«‹è¯»å–æ•°æ®"""
    print("="*60)
    print("ğŸ” æµ‹è¯•ï¼šAgent ç‹¬ç«‹æ•°æ®è¯»å–èƒ½åŠ›")
    print("="*60)

    dataset_path = "data/samples/sales_2024_Q1.csv"

    if not Path(dataset_path).exists():
        print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}")
        return False

    print(f"\nâœ… æ•°æ®é›†: {dataset_path}")

    # æ¨¡æ‹Ÿ Data Explorer
    print("\n1ï¸âƒ£  Data Explorer Agent:")
    df1 = pd.read_csv(dataset_path)
    print(f"   âœ… è¯»å–æ•°æ®: {df1.shape}")
    print(f"   âœ… åˆ—å: {list(df1.columns)}")
    print(f"   âœ… é”€å”®å‡å€¼: {df1['sales'].mean():.2f}")
    print(f"   âœ… åˆ©æ¶¦æ€»é¢: {df1['profit'].sum():,.0f}")

    # æ¨¡æ‹Ÿ Analystï¼ˆç‹¬ç«‹è¯»å–ï¼‰
    print("\n2ï¸âƒ£  Analyst Agent (ç‹¬ç«‹è¯»å–):")
    df2 = pd.read_csv(dataset_path)  # ä¸ä¾èµ– df1
    print(f"   âœ… è¯»å–æ•°æ®: {df2.shape}")
    print(f"   âœ… é”€å”®æ ‡å‡†å·®: {df2['sales'].std():.2f}")
    print(f"   âœ… æœ€å¤§é”€å”®é¢: {df2['sales'].max()}")
    print(f"   âœ… æœ€å°é”€å”®é¢: {df2['sales'].min()}")

    # è®¡ç®—ç›¸å…³æ€§
    corr = df2[['sales', 'profit', 'customers', 'orders']].corr()
    print(f"   âœ… é”€å”®é¢ä¸åˆ©æ¶¦ç›¸å…³æ€§: {corr.loc['sales', 'profit']:.4f}")

    # æ¨¡æ‹Ÿ PandaAI Agentï¼ˆç‹¬ç«‹è¯»å–ï¼‰
    print("\n3ï¸âƒ£  PandaAI Agent (ç‹¬ç«‹è¯»å–):")
    df3 = pd.read_csv(dataset_path)  # ä¸ä¾èµ– df1, df2
    print(f"   âœ… è¯»å–æ•°æ®: {df3.shape}")

    # è½¬æ¢ä¸ºå­—å…¸ï¼ˆæ¨¡æ‹Ÿ PandaAI çš„æ“ä½œï¼‰
    data_dict = df3.to_dict(orient='records')
    print(f"   âœ… è½¬æ¢ä¸ºå­—å…¸: {len(data_dict)} æ¡è®°å½•")

    # æŒ‰ç±»åˆ«åˆ†ç»„ç»Ÿè®¡
    category_stats = df3.groupby('category')['sales'].agg(['mean', 'sum', 'count']).round(0)
    print(f"   âœ… æŒ‰ç±»åˆ«ç»Ÿè®¡:")
    for cat, row in category_stats.iterrows():
        print(f"      - {cat}: å‡å€¼={row['mean']:.0f}, æ€»é¢={row['sum']:,.0f}")

    # æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡
    region_stats = df3.groupby('region')['profit'].sum().sort_values(ascending=False)
    print(f"   âœ… æŒ‰åœ°åŒºåˆ©æ¶¦æ’å:")
    for region, profit in region_stats.items():
        print(f"      - {region}: {profit:,.0f}")

    # æ¨¡æ‹Ÿ Reporterï¼ˆæ•´åˆç»“æœï¼‰
    print("\n4ï¸âƒ£  Reporter Agent (æ•´åˆç»“æœ):")
    print(f"   âœ… æ”¶åˆ° Data Explorer çš„è¾“å‡º: æ•°æ®æ¦‚è§ˆ")
    print(f"   âœ… æ”¶åˆ° Analyst çš„è¾“å‡º: ç»Ÿè®¡åˆ†æ")
    print(f"   âœ… æ”¶åˆ° PandaAI çš„è¾“å‡º: æ´å¯Ÿåˆ†æ")
    print(f"   âœ… ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")

    print("\n" + "="*60)
    print("âœ… æµ‹è¯•é€šè¿‡ï¼æ¯ä¸ª Agent éƒ½å¯ä»¥ç‹¬ç«‹è¯»å–æ•°æ®")
    print("="*60)

    return True


def generate_mock_report():
    """ç”Ÿæˆæ¨¡æ‹ŸæŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“„ ç”Ÿæˆæ¨¡æ‹Ÿåˆ†ææŠ¥å‘Š")
    print("="*60)

    dataset_path = "data/samples/sales_2024_Q1.csv"
    df = pd.read_csv(dataset_path)

    report = f"""# ğŸ“Š 2024å¹´Q1é”€å”®æ•°æ®åˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šåˆ†æäº†2024å¹´ç¬¬ä¸€å­£åº¦ï¼ˆ1-3æœˆï¼‰çš„é”€å”®æ•°æ®ï¼Œæ¶µç›–{df['sales'].sum():,.0f}å…ƒçš„æ€»é”€å”®é¢å’Œ{df['profit'].sum():,.0f}å…ƒçš„æ€»åˆ©æ¶¦ã€‚

## 1. æ•°æ®æ¦‚è§ˆ

### åŸºæœ¬ä¿¡æ¯
- **æ•°æ®è§„æ¨¡**: {len(df):,} è¡Œ Ã— {len(df.columns)} åˆ—
- **æ—¶é—´èŒƒå›´**: {df['date'].min()} è‡³ {df['date'].max()}
- **åœ°åŒºæ•°é‡**: {df['region'].nunique()} ä¸ª
- **ç±»åˆ«æ•°é‡**: {df['category'].nunique()} ä¸ª

### å­—æ®µåˆ—è¡¨
{chr(10).join([f"- **{col}**: {dtype}" for col, dtype in df.dtypes.items()])}

## 2. ç»Ÿè®¡åˆ†æ

### å…³é”®æŒ‡æ ‡
- **æ€»é”€å”®é¢**: {df['sales'].sum():,.0f} å…ƒ
- **æ€»åˆ©æ¶¦**: {df['profit'].sum():,.0f} å…ƒ
- **å¹³å‡åˆ©æ¶¦ç‡**: {(df['profit'].sum() / df['sales'].sum() * 100):.1f}%
- **æ€»å®¢æˆ·æ•°**: {df['customers'].sum():,} ä½
- **æ€»è®¢å•æ•°**: {df['orders'].sum():,} ä¸ª

### é”€å”®è¶‹åŠ¿
- **æ—¥å‡é”€å”®é¢**: {df['sales'].mean():,.0f} å…ƒ
- **é”€å”®æ³¢åŠ¨**: {df['sales'].std():,.0f} å…ƒ (æ ‡å‡†å·®)
- **æœ€é«˜å•æ—¥é”€å”®**: {df['sales'].max():,} å…ƒ
- **æœ€ä½å•æ—¥é”€å”®**: {df['sales'].min():,} å…ƒ

### ç›¸å…³æ€§åˆ†æ
- **é”€å”®é¢ä¸åˆ©æ¶¦**: {df[['sales', 'profit']].corr().iloc[0, 1]:.4f}
- **å®¢æˆ·æ•°ä¸è®¢å•æ•°**: {df[['customers', 'orders']].corr().iloc[0, 1]:.4f}

## 3. åˆ†ç»„åˆ†æ

### æŒ‰ç±»åˆ«
"""

    # ç±»åˆ«åˆ†æ
    category_stats = df.groupby('category').agg({
        'sales': 'sum',
        'profit': 'sum',
        'orders': 'sum'
    }).sort_values('sales', ascending=False)

    for cat, row in category_stats.iterrows():
        report += f"\n#### {cat}\n"
        report += f"- é”€å”®é¢: {row['sales']:,.0f} å…ƒ\n"
        report += f"- åˆ©æ¶¦: {row['profit']:,.0f} å…ƒ\n"
        report += f"- è®¢å•æ•°: {row['orders']:,.0f} ä¸ª\n"

    report += "\n### æŒ‰åœ°åŒº\n"

    # åœ°åŒºåˆ†æ
    region_stats = df.groupby('region').agg({
        'sales': 'sum',
        'profit': 'sum',
        'customers': 'sum'
    }).sort_values('sales', ascending=False)

    for region, row in region_stats.iterrows():
        report += f"\n#### {region}\n"
        report += f"- é”€å”®é¢: {row['sales']:,.0f} å…ƒ\n"
        report += f"- åˆ©æ¶¦: {row['profit']:,.0f} å…ƒ\n"
        report += f"- å®¢æˆ·æ•°: {row['customers']:,.0f} ä½\n"

    report += f"""
## 4. æ´å¯Ÿä¸å»ºè®®

### å…³é”®å‘ç°
1. **æœ€ä½³è¡¨ç°ç±»åˆ«**: {category_stats.index[0]}ï¼Œè´¡çŒ®äº† {category_stats.iloc[0]['sales']:,.0f} å…ƒé”€å”®é¢
2. **æœ€ä½³è¡¨ç°åœ°åŒº**: {region_stats.index[0]}ï¼Œå®ç°äº† {region_stats.iloc[0]['sales']:,.0f} å…ƒé”€å”®é¢
3. **å¹³å‡åˆ©æ¶¦ç‡**: {(df['profit'].sum() / df['sales'].sum() * 100):.1f}%

### å»ºè®®
1. **åŠ å¤§ {category_stats.index[0]} çš„æŠ•å…¥**ï¼šè¯¥ç±»åˆ«è¡¨ç°æœ€ä½³ï¼Œå¯è€ƒè™‘å¢åŠ åº“å­˜å’Œè¥é”€
2. **æ‹“å±• {region_stats.index[0]} å¸‚åœº**ï¼šè¯¥åœ°åŒºé”€å”®é¢é¢†å…ˆï¼Œå¯ä½œä¸ºé‡ç‚¹å‘å±•åŒºåŸŸ
3. **æå‡è¿è¥æ•ˆç‡**ï¼šå½“å‰åˆ©æ¶¦ç‡ä¸º {(df['profit'].sum() / df['sales'].sum() * 100):.1f}%ï¼Œä»æœ‰æå‡ç©ºé—´

## 5. é™„å½•

### æ•°æ®è´¨é‡
- æ•°æ®å®Œæ•´æ€§: âœ… æ— ç¼ºå¤±å€¼
- æ•°æ®ä¸€è‡´æ€§: âœ… æ ¼å¼ç»Ÿä¸€
- æ•°æ®å‡†ç¡®æ€§: âœ… æ•°å€¼åˆç†

### åˆ†ææ–¹æ³•
- æè¿°æ€§ç»Ÿè®¡
- ç›¸å…³æ€§åˆ†æ
- åˆ†ç»„èšåˆ
- è¶‹åŠ¿åˆ†æ

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}*
*åˆ†æå·¥å…·: DataInsight Pro v2.0_fixed*
"""

    # ä¿å­˜æŠ¥å‘Š
    report_file = "mock_analysis_report.md"
    Path(report_file).write_text(report)

    print(f"\nâœ… æ¨¡æ‹ŸæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    print(f"   - å¤§å°: {len(report):,} å­—ç¬¦")
    print(f"   - è¡Œæ•°: {len(report.split(chr(10)))} è¡Œ")

    # æ˜¾ç¤ºé¢„è§ˆ
    print("\nğŸ“„ æŠ¥å‘Šé¢„è§ˆ:")
    print(report[:800])
    print("...\n")

    return report


def main():
    print("\nğŸš€ DataInsight Pro - å¿«é€ŸéªŒè¯æµ‹è¯•")
    print("="*60)
    print("ç›®çš„: éªŒè¯ä¿®å¤åçš„æ•°æ®æµæ˜¯å¦æ­£å¸¸å·¥ä½œ")
    print("="*60)

    # æµ‹è¯• 1: æ•°æ®æµ
    if test_data_flow():
        # æµ‹è¯• 2: ç”ŸæˆæŠ¥å‘Š
        generate_mock_report()

        print("\n" + "="*60)
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("="*60)

        print("\nâœ… æ ¸å¿ƒéªŒè¯:")
        print("   1. æ¯ä¸ª Agent å¯ä»¥ç‹¬ç«‹è¯»å–æ•°æ®")
        print("   2. ä¸ä¾èµ–å‰ä¸€ä¸ª Agent çš„è¾“å‡º")
        print("   3. å¯ä»¥æ‰§è¡ŒçœŸæ­£çš„æ•°æ®åˆ†æ")

        print("\nğŸ“ ç”Ÿæˆæ–‡ä»¶:")
        print("   - mock_analysis_report.md (æ¨¡æ‹ŸæŠ¥å‘Š)")

        print("\nğŸ’¡ è¯´æ˜:")
        print("   æ­¤æµ‹è¯•éªŒè¯äº†ä¿®å¤ç‰ˆæœ¬çš„æ ¸å¿ƒæ”¹è¿›ï¼š")
        print("   - ç§»é™¤ context ä¾èµ–")
        print("   - æ¯ä¸ª Agent ç›´æ¥è¯»å–æ•°æ®æ–‡ä»¶")
        print("   - å¯ä»¥çœŸæ­£æ‰§è¡Œç»Ÿè®¡åˆ†æ")

        print("\nğŸš€ ä¸‹ä¸€æ­¥:")
        print("   å¦‚æœè¦æµ‹è¯•å®Œæ•´çš„ CrewAI æµç¨‹ï¼ˆéœ€è¦ LLM APIï¼‰ï¼Œ")
        print("   è¯·ç¡®ä¿å®‰è£…äº†å…¼å®¹ç‰ˆæœ¬çš„ä¾èµ–å¹¶é…ç½® API Key")

    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main()
